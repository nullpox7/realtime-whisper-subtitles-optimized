# Real-time Whisper Subtitles - GPU Optimized Environment Variables (v2.2.3)
# CUDA 11.8 + PyTorch 2.1.2 ultra-stable configuration - All symbol errors resolved
# Copy this file to .env for maximum GPU performance and stability
# Encoding: UTF-8

# ========================================
# Server Configuration
# ========================================
HOST=0.0.0.0
PORT=8000
DEBUG=false

# ========================================
# Whisper Model Configuration (Maximum Accuracy with large-v3)
# ========================================
WHISPER_MODEL=large-v3
LANGUAGE=auto

# ========================================
# Audio Processing Configuration
# ========================================
SAMPLE_RATE=16000
CHUNK_SIZE=1024
VAD_MODE=3

# ========================================
# High Accuracy Processing Configuration
# ========================================
BEAM_SIZE=5
BEST_OF=5
TEMPERATURE=0.0
LENGTH_PENALTY=1.0
PATIENCE=1.0

# ========================================
# Advanced Transcription Settings
# ========================================
ENABLE_WORD_TIMESTAMPS=true
VAD_FILTER=true
COMPRESSION_RATIO_THRESHOLD=2.4
LOG_PROB_THRESHOLD=-1.0
NO_SPEECH_THRESHOLD=0.6
CONDITION_ON_PREVIOUS_TEXT=false

# ========================================
# GPU Performance Configuration (CUDA 11.8 Ultra-Stable)
# ========================================
DEVICE=cuda
COMPUTE_TYPE=float16
MAX_WORKERS=4
BATCH_SIZE=16

# ========================================
# CUDA 11.8 Optimization (Maximum Stability)
# ========================================
CUDA_VISIBLE_DEVICES=all
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=compute,utility
CUDA_CACHE_PATH=/tmp/cuda_cache
TORCH_CUDA_ARCH_LIST=7.0;7.5;8.0;8.6;8.9

# ========================================
# GPU Memory Management (CUDA 11.8 Stable)
# ========================================
CUDA_MEMORY_FRACTION=0.85
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
CUDA_MODULE_LOADING=LAZY

# ========================================
# C++ ABI Compatibility (Critical for Symbol Resolution)
# ========================================
_GLIBCXX_USE_CXX11_ABI=1
TORCH_CXX_FLAGS=-D_GLIBCXX_USE_CXX11_ABI=1

# ========================================
# Memory Allocator Stabilization
# ========================================
MALLOC_TRIM_THRESHOLD_=131072
MALLOC_MMAP_THRESHOLD_=131072
MALLOC_MMAP_MAX_=65536

# ========================================
# Paths Configuration
# ========================================
MODEL_PATH=/app/data/models
OUTPUT_PATH=/app/data/outputs
LOG_PATH=/app/data/logs

# ========================================
# Logging Configuration
# ========================================
LOG_LEVEL=INFO

# ========================================
# Security Configuration
# ========================================
RATE_LIMIT=100
MAX_UPLOAD_SIZE=100

# ========================================
# CORS Configuration
# ========================================
ENABLE_CORS=true
CORS_ORIGINS=*

# ========================================
# Localization Configuration
# ========================================
TZ=Asia/Tokyo
LANG=en_US.UTF-8
LC_ALL=en_US.UTF-8

# ========================================
# Docker Configuration
# ========================================
DOCKER_NETWORK=whisper-network

# ========================================
# Stability Settings (Added for v2.2.3)
# ========================================
# Disable JIT compilation for maximum stability
NUMBA_DISABLE_JIT=1
NUMBA_CACHE_DIR=/dev/null
NUMBA_THREADING_LAYER=workqueue
NUMBA_PARALLEL=0
