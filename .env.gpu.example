# Real-time Whisper Subtitles - GPU Optimized Environment Variables (v2.2.4)
# CUDA 12.0 + PyTorch 2.1.0 stable configuration - memory-safe and compatible
# Copy this file to .env for maximum GPU performance
# Encoding: UTF-8

# ========================================
# Server Configuration
# ========================================
HOST=0.0.0.0
PORT=8000
DEBUG=false

# ========================================
# Whisper Model Configuration (Maximum Accuracy with large-v3)
# ========================================
WHISPER_MODEL=large-v3
LANGUAGE=auto

# ========================================
# Audio Processing Configuration
# ========================================
SAMPLE_RATE=16000
CHUNK_SIZE=1024
VAD_MODE=3

# ========================================
# High Accuracy Processing Configuration
# ========================================
BEAM_SIZE=5
BEST_OF=5
TEMPERATURE=0.0
LENGTH_PENALTY=1.0
PATIENCE=1.0

# ========================================
# Advanced Transcription Settings
# ========================================
ENABLE_WORD_TIMESTAMPS=true
VAD_FILTER=true
COMPRESSION_RATIO_THRESHOLD=2.4
LOG_PROB_THRESHOLD=-1.0
NO_SPEECH_THRESHOLD=0.6
CONDITION_ON_PREVIOUS_TEXT=false

# ========================================
# GPU Performance Configuration (CUDA 12.0 Optimized)
# ========================================
DEVICE=cuda
COMPUTE_TYPE=float16
MAX_WORKERS=2
BATCH_SIZE=8

# ========================================
# CUDA 12.0 Optimization
# ========================================
CUDA_VISIBLE_DEVICES=all
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=compute,utility
CUDA_CACHE_PATH=/tmp/cuda_cache
TORCH_CUDA_ARCH_LIST=7.0;7.5;8.0;8.6;8.9;9.0

# ========================================
# GPU Memory Management (CUDA 12.0)
# ========================================
CUDA_MEMORY_FRACTION=0.8
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128,expandable_segments:True
CUDA_MODULE_LOADING=LAZY
TORCH_CUDNN_V8_API_ENABLED=1

# ========================================
# Memory Safety Configuration
# ========================================
LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libjemalloc.so.2
MALLOC_CONF=dirty_decay_ms:1000,muzzy_decay_ms:1000
NUMBA_DISABLE_JIT=1
NUMBA_CACHE_DIR=/dev/null
NUMBA_THREADING_LAYER=workqueue
NUMBA_PARALLEL=0
NUMBA_DISABLE_PERFORMANCE_WARNINGS=1
NUMBA_DISABLE_CUDA=1
PYTHONHASHSEED=0
PYTHONMALLOC=malloc

# ========================================
# Paths Configuration
# ========================================
MODEL_PATH=/app/data/models
OUTPUT_PATH=/app/data/outputs
LOG_PATH=/app/data/logs

# ========================================
# Logging Configuration
# ========================================
LOG_LEVEL=INFO

# ========================================
# Security Configuration
# ========================================
RATE_LIMIT=100
MAX_UPLOAD_SIZE=100

# ========================================
# CORS Configuration
# ========================================
ENABLE_CORS=true
CORS_ORIGINS=*

# ========================================
# Localization Configuration
# ========================================
TZ=Asia/Tokyo
LANG=en_US.UTF-8
LC_ALL=en_US.UTF-8

# ========================================
# Docker Configuration
# ========================================
DOCKER_NETWORK=whisper-network