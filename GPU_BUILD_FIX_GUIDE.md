# GPU Docker Build Fix - Usage Guide

## ? CUDA 12.9 Build Issues Fixed

?????????CUDA 12.9???Dockerfile?????????????????????

### ? Quick Fix????

```bash
# ??????????????????
chmod +x fix_gpu_docker_build.sh
./fix_gpu_docker_build.sh
```

### ? ????

1. **CUDA 12.9 ? CUDA 12.4**: ??????CUDA????????
2. **Python 3.11**: Ubuntu 22.04?????????????
3. **?????????**: ????????????
4. **PyTorch**: CUDA 12.4??????
5. **?????????**: ?????????????????

### ? ????

#### ????????

```bash
# 1. ????????????????????
git pull origin main

# 2. ????????
cp .env.gpu.working.example .env

# 3. GPU?????
docker-compose -f docker-compose.gpu.working.yml build --no-cache

# 4. ??
docker-compose -f docker-compose.gpu.working.yml up -d

# 5. ??
curl http://localhost:8000/health
```

#### ????????????

```bash
# ??????????????
./fix_gpu_docker_build.sh
```

### ? ?????????

- `Dockerfile.gpu.working` - ???GPU Dockerfile
- `requirements.gpu.working.txt` - ???Python????
- `docker-compose.gpu.working.yml` - ???docker-compose
- `.env.gpu.working.example` - GPU??????
- `fix_gpu_docker_build.sh` - ?????????

### ? ????

```bash
# ????????????????
curl http://localhost:8000/health

# ???????:
{
  "status": "healthy",
  "gpu_available": true,
  "model_loaded": true,
  "version": "2.2.1"
}
```

### ?? ??????

```bash
# ?????
docker-compose -f docker-compose.gpu.working.yml logs -f whisper-subtitles-gpu

# ???
docker-compose -f docker-compose.gpu.working.yml restart

# ??
docker-compose -f docker-compose.gpu.working.yml down

# GPU??
watch -n 1 nvidia-smi
```

### ? ???????????

#### ??????????

1. **NVIDIA Container Toolkit**???:
   ```bash
   docker run --rm --gpus all nvidia/cuda:12.4.1-runtime-ubuntu22.04 nvidia-smi
   ```

2. **Docker????**:
   ```bash
   sudo systemctl restart docker
   ```

3. **???CPU?**:
   ```bash
   docker-compose up -d  # CPU????
   ```

#### ???????

| ??? | ???? |
|--------|----------|
| `nvidia/cuda:12.9.0 image not found` | ???????????CUDA 12.4?????? |
| `Python 3.11 installation failed` | ????????PPA??????? |
| `Package dependency conflicts` | ???requirements.gpu.working.txt??? |
| `PyTorch CUDA mismatch` | CUDA 12.4??PyTorch????? |
| `Permission denied` | `sudo chmod +x fix_gpu_docker_build.sh` |

### ? GPU??????

#### GPU?????

```bash
# RTX 4090/4080 (16GB+ VRAM)
BATCH_SIZE=32
MAX_WORKERS=6
CUDA_MEMORY_FRACTION=0.9
WHISPER_MODEL=large-v3

# RTX 4070/3080 (12GB VRAM) - ??
BATCH_SIZE=16
MAX_WORKERS=4
CUDA_MEMORY_FRACTION=0.85
WHISPER_MODEL=large-v3

# RTX 3060/4060 (8GB VRAM)
BATCH_SIZE=8
MAX_WORKERS=2
CUDA_MEMORY_FRACTION=0.8
WHISPER_MODEL=medium

# GTX 1660 Ti/2060 (6GB VRAM)
BATCH_SIZE=4
MAX_WORKERS=1
CUDA_MEMORY_FRACTION=0.75
WHISPER_MODEL=small
```

### ? ????

| GPU | VRAM | ??? | RTF | ?? |
|-----|------|--------|-----|------|
| RTX 4090 | 24GB | large-v3 | 0.15x | 97%+ |
| RTX 4070 | 12GB | large-v3 | 0.22x | 97%+ |
| RTX 3080 | 10GB | large-v3 | 0.28x | 97%+ |
| RTX 3060 | 8GB | medium | 0.45x | 95%+ |

### ? ?????

#### monitoring??????

```bash
# Prometheus + Grafana ??????
docker-compose -f docker-compose.gpu.working.yml --profile monitoring up -d

# Grafana ????: http://localhost:3000 (admin/admin)
```

#### ?????????

```bash
# .env?????????
echo "WHISPER_MODEL=medium" >> .env
echo "BEAM_SIZE=10" >> .env
echo "TEMPERATURE=0.2" >> .env

# ??????????
docker-compose -f docker-compose.gpu.working.yml restart
```

### ? Web Interface ???

1. **?????????**: http://localhost:8000
2. **?????????**: ???????????
3. **???????**: `F`??????????????
4. **????**: `Space`??????Start Recording????
5. **?????**: `C`??????Clear????

### ? ????????????

#### OBS Studio ????

1. **?????????**
2. **URL??**: `http://localhost:8000`
3. **??????????**: ?????`F`?????
4. **????**: CSS ? `background: transparent;` ???

#### ???????

```bash
# ???????????
WHISPER_MODEL=large-v3        # ????
LANGUAGE=auto                 # ??????
ENABLE_WORD_TIMESTAMPS=true   # ???????????
VAD_FILTER=true              # ??????????
BATCH_SIZE=16                # ????????
```

### ? ??????

#### ???????

```bash
# ??????????
docker-compose -f docker-compose.gpu.working.yml logs whisper-subtitles-gpu

# GPU????
nvidia-smi -l 1

# ???????
docker-compose -f docker-compose.gpu.working.yml ps

# ?????????
curl -s http://localhost:8000/health | jq
```

### ? ????????

- **GPU?????**: [README_GPU.md](README_GPU.md)
- **????????**: [README.md](README.md)
- **???????????**: [GitHub Issues](https://github.com/nullpox7/realtime-whisper-subtitles-optimized/issues)

### ? Tips

1. **?????**: ????????????????????large-v3??1.5GB?
2. **?????**: `CUDA_MEMORY_FRACTION`????????
3. **????**: `CHUNK_SIZE`?????????
4. **????**: `BEAM_SIZE`?????????????????

---

## ? ????

????????????????????Issue??????????

```bash
# ?????????
nvidia-smi
docker --version
docker-compose --version
uname -a

# ?????
docker-compose -f docker-compose.gpu.working.yml logs whisper-subtitles-gpu > error.log
```

? **GPU?????????????????????????**