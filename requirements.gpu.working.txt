# Real-time Whisper Subtitles - GPU Working Dependencies (Fixed)
# CUDA 12.4 compatible versions - Guaranteed to install successfully
# Encoding: UTF-8

# Web Framework (tested stable versions)
fastapi==0.109.2
uvicorn[standard]==0.27.1
websockets==12.0
jinja2==3.1.3
python-multipart==0.0.9

# PyTorch with CUDA 12.4 support (installed separately in Dockerfile)
# torch==2.4.1+cu124 --index-url https://download.pytorch.org/whl/cu124
# torchaudio==2.4.1+cu124 --index-url https://download.pytorch.org/whl/cu124

# Core AI/ML (stable GPU optimized versions)
faster-whisper==1.0.1
transformers==4.38.2
accelerate==0.27.2

# Audio Processing (proven compatible versions)
librosa==0.10.1
soundfile==0.12.1

# Scientific Computing - stable versions for CUDA 12.4
numpy>=1.24.0,<2.0.0
scipy==1.12.0

# Numba and LLVM - compatible with CUDA 12.4
numba==0.59.0
llvmlite==0.42.0

# Redis client for caching
redis==5.0.1
aioredis==2.0.1

# System utilities
psutil==5.9.8
python-dotenv==1.0.1
requests==2.31.0
aiofiles==23.2.1

# Production server
gunicorn==21.2.0

# Monitoring and metrics
prometheus-client==0.20.0

# Essential utilities
tqdm==4.66.2
packaging==23.2

# Async HTTP client
httpx==0.26.0

# Logging utilities
structlog==24.1.0

# Date/time handling
python-dateutil==2.8.2

# Configuration management
pyyaml==6.0.1

# Memory optimization
pympler==0.9

# Additional ML/Audio dependencies (tested versions)
resampy==0.4.2
audioread==3.0.1
pooch>=1.8.0
joblib>=1.3.0
threadpoolctl>=3.1.0

# GPU memory management (compatible with CUDA 12.4)
nvidia-ml-py==12.535.133

# Additional performance libraries
orjson==3.9.15
msgpack==1.0.7

# Development tools (optional)
ipython==8.21.0

# Model downloading and caching
huggingface-hub==0.20.3

# Optional CUDA optimizations (install only if available)
# cupy-cuda12x==13.0.0  # Commented out for compatibility
# triton==2.2.0  # Commented out for compatibility