# Real-time Whisper Subtitles - GPU Lightweight Dockerfile
# Minimal dependencies for maximum compatibility
# Author: Real-time Whisper Subtitles Team
# Encoding: UTF-8

# Use CUDA 12.4 runtime (smaller and more stable than devel)
FROM nvidia/cuda:12.4.0-runtime-ubuntu22.04

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV PIP_NO_CACHE_DIR=1
ENV LOG_PATH=/app/data/logs

# CUDA and GPU optimization environment variables
ENV CUDA_VISIBLE_DEVICES=all
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Install essential packages only
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    python3 \
    python3-pip \
    python3-dev \
    build-essential \
    curl \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# Create app user
RUN groupadd -r appuser && useradd -r -g appuser -s /bin/bash appuser

# Set working directory
WORKDIR /app

# Create symbolic link for python
RUN ln -s /usr/bin/python3 /usr/bin/python

# Copy requirements file
COPY requirements.gpu.txt .

# Upgrade pip
RUN python3 -m pip install --upgrade pip setuptools wheel

# Install PyTorch with CUDA 12.4 support
RUN python3 -m pip install torch==2.4.1+cu124 torchaudio==2.4.1+cu124 --index-url https://download.pytorch.org/whl/cu124

# Install other Python dependencies
RUN python3 -m pip install --no-cache-dir -r requirements.gpu.txt

# Create directories
RUN mkdir -p /app/data/{models,outputs,logs,cache} \
    && mkdir -p /app/static /app/templates /app/src \
    && mkdir -p /home/appuser/.cache \
    && chown -R appuser:appuser /app /home/appuser

# Copy application files
COPY src/ ./src/
COPY static/ ./static/
COPY templates/ ./templates/
COPY .env.gpu.example* ./

# Set permissions
RUN chown -R appuser:appuser /app

# Switch to non-root user
USER appuser

# Create user directories
RUN mkdir -p /app/data/{models/whisper,outputs,logs,cache} \
    && mkdir -p /home/appuser/.cache/torch

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=120s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Environment variables for GPU optimization
ENV HOST=0.0.0.0
ENV PORT=8000
ENV WHISPER_MODEL=base
ENV LANGUAGE=auto
ENV DEVICE=cuda
ENV COMPUTE_TYPE=float16
ENV BATCH_SIZE=8
ENV MAX_WORKERS=2

# Default command
CMD ["python3", "-m", "uvicorn", "src.web_interface:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]